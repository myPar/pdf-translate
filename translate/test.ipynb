{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import httpx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_api_key() -> dict:\n",
    "    with open('oauth_key') as f:\n",
    "        oauth_key = f.read()\n",
    "    if oauth_key == \"\":\n",
    "        raise Exception('no oauth key provided')\n",
    "    data = {\"yandexPassportOauthToken\": oauth_key}\n",
    "    try:\n",
    "        response = httpx.post(url='https://iam.api.cloud.yandex.net/iam/v1/tokens', json=data)\n",
    "        response.raise_for_status()\n",
    "        print(f'get api key response code={response.status_code}')\n",
    "    except httpx.HTTPStatusError as e:\n",
    "        raise Exception(f'error response: status={e.response.status_code}; {repr(e)}')\n",
    "    except httpx.RequestError as e:\n",
    "        raise Exception(f'request error: {str(e)}')\n",
    "\n",
    "    return json.loads(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get api key response code=200\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    r = get_api_key()\n",
    "except Exception as e:\n",
    "    print(str(e))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "'b\\'{\\\\n \"iamToken\": \"t1.9euelZrLyJiYk57PmI6WkZaTlImMlu3rnpWaypeOkpXMlJqLypqNyJuOz5jl8_c7UnlI-e9ECBpt_t3z93sAd0j570QIGm3-zef1656VmpXMnczMnpqJj8qQiZ2OlZKe7_zF656VmpXMnczMnpqJj8qQiZ2OlZKe.L2FppnYr2XMEfv_ntishPKnBIJTN8kpCf4kkKsTcz6wcJyEVMKtiwaA1nH2vaTPVTrKrDtrn4NUC5tBZhohjDQ\",\\\\n \"expiresAt\": \"2024-09-12T01:10:28.307854267Z\"\\\\n}\\\\n\\''"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(r.content)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "{'iamToken': 't1.9euelZrLyJiYk57PmI6WkZaTlImMlu3rnpWaypeOkpXMlJqLypqNyJuOz5jl8_c7UnlI-e9ECBpt_t3z93sAd0j570QIGm3-zef1656VmpXMnczMnpqJj8qQiZ2OlZKe7_zF656VmpXMnczMnpqJj8qQiZ2OlZKe.L2FppnYr2XMEfv_ntishPKnBIJTN8kpCf4kkKsTcz6wcJyEVMKtiwaA1nH2vaTPVTrKrDtrn4NUC5tBZhohjDQ',\n 'expiresAt': '2024-09-12T01:10:28.307854267Z'}"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = json.loads(r.content)\n",
    "obj"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "'t1.9euelZrLyJiYk57PmI6WkZaTlImMlu3rnpWaypeOkpXMlJqLypqNyJuOz5jl8_c7UnlI-e9ECBpt_t3z93sAd0j570QIGm3-zef1656VmpXMnczMnpqJj8qQiZ2OlZKe7_zF656VmpXMnczMnpqJj8qQiZ2OlZKe.L2FppnYr2XMEfv_ntishPKnBIJTN8kpCf4kkKsTcz6wcJyEVMKtiwaA1nH2vaTPVTrKrDtrn4NUC5tBZhohjDQ'"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj['iamToken']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "'2024-09-12T01:10:28.307854267Z'"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj['expiresAt']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "dict"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(obj)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import httpx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "client = httpx.AsyncClient()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def close_client():\n",
    "    async def close():\n",
    "        await client.aclose()\n",
    "    try:\n",
    "        with asyncio.Runner() as runner:\n",
    "            runner.run(close())\n",
    "        print(f'async httpx client is closed.', flush=True)\n",
    "    except Exception as e:\n",
    "        print(f'FATAL: exeption while closing httpx async client:{str(e)}', file=sys.stderr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'Communicated by David Haussler \\nBayesian Interpolation \\nDavid J. C. MacKay’ \\nComputation and Neural Systems, California Institute of Technology 139-74, \\nPasadena, CA 91225 USA \\nAlthough Bayesian analysis has been in use since Laplace, the Bayesian \\nmethod of model-comparison has only recently been developed in \\ndepth. In this paper, the Bayesian approach to regularization and \\nmodel-comparison is demonstrated by studying the inference prob- \\nlem of interpolating noisy data. The concepts and methods described \\nare quite general and can be applied to many other data modeling \\nproblems. Regularizing constants are set by examining their posterior \\nprobability distribution. Alternative regularizers (priors) and alterna- \\ntive basis sets are objectively compared by evaluating the evidence for \\nthem. ”Occam’s razor” is automatically embodied by this process. The \\nway in which Bayes infers the values of regularizing constants and \\nnoise levels has an elegant interpretation in terms of the effective num- \\nber of parameters determined by the data set. This framework is due \\nto Gull and Skilling. \\n1 Data Modeling and Occam’s Razor \\nIn science, a central task is to develop and compare models to account \\nfor the data that are gathered. In particular this is true in the problems of \\nlearning, pattern classification, interpolation and clustering. Two levels \\nof inference are involved in the task of data modeling (Fig. 1). At the first \\nlevel of inference, we assume that one of the models that we invented is \\ntrue, and we fit that model to the data. Typically a model includes some \\nfree parameters; fitting the model to the data involves inferring what \\nvalues those parameters should probably take, given the data. The results \\nof this inference are often summarized by the most probable parameter \\nvalues and error bars on those parameters. This is repeated for each \\nmodel. The second level of inference is the task of model comparison. \\nHere, we wish to compare the models in the light of the data, and assign \\nsome sort of preference or ranking to the alternatives.’ \\n*Present address: Darwin College, Cambridge CB3 9EU, U.K. \\n’Note that both levels of inference are distinct from decision theory. The goal of infer- \\nence is, given a defined hypothesis space and a particular data set, to assign probabilities \\nto hypotheses. Decision theory typically chooses between alternative actions on the ba- \\nsis of these probabilities so as to minimize the expectation of a “loss function.” This \\npaper concerns inference alone and no loss functions or utilities are involved. \\nNeural Computation 4, 415-447 (1992) @ 1992 Massachusetts Institute of Technology '"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = PdfReader('Bayesian Interpolation.pdf')\n",
    "page = reader.pages[0]\n",
    "p_text = page.extract_text()\n",
    "p_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'Communicated by David Haussler Bayesian Interpolation David J. C. MacKay’ Computation and Neural Systems, California Institute of Technology 139-74, Pasadena, CA 91225 USA Although Bayesian analysis has been in use since Laplace, the Bayesian method of model-comparison has only recently been developed in depth. In this paper, the Bayesian approach to regularization and model-comparison is demonstrated by studying the inference prob- lem of interpolating noisy data. The concepts and methods described are quite general and can be applied to many other data modeling problems. Regularizing constants are set by examining their posterior probability distribution. Alternative regularizers (priors) and alterna- tive basis sets are objectively compared by evaluating the evidence for them. ”Occam’s razor” is automatically embodied by this process. The way in which Bayes infers the values of regularizing constants and noise levels has an elegant interpretation in terms of the effective num- ber of parameters determined by the data set. This framework is due to Gull and Skilling. 1 Data Modeling and Occam’s Razor In science, a central task is to develop and compare models to account for the data that are gathered. In particular this is true in the problems of learning, pattern classification, interpolation and clustering. Two levels of inference are involved in the task of data modeling (Fig. 1). At the first level of inference, we assume that one of the models that we invented is true, and we fit that model to the data. Typically a model includes some free parameters; fitting the model to the data involves inferring what values those parameters should probably take, given the data. The results of this inference are often summarized by the most probable parameter values and error bars on those parameters. This is repeated for each model. The second level of inference is the task of model comparison. Here, we wish to compare the models in the light of the data, and assign some sort of preference or ranking to the alternatives.’ *Present address: Darwin College, Cambridge CB3 9EU, U.K. ’Note that both levels of inference are distinct from decision theory. The goal of infer- ence is, given a defined hypothesis space and a particular data set, to assign probabilities to hypotheses. Decision theory typically chooses between alternative actions on the ba- sis of these probabilities so as to minimize the expectation of a “loss function.” This paper concerns inference alone and no loss functions or utilities are involved. Neural Computation 4, 415-447 (1992) @ 1992 Massachusetts Institute of Technology '"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_text = p_text.replace('\\n', '')\n",
    "p_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "[[10, 10, 10, 10, 10, 10, 10],\n [10, 10, 10, 10, 10, 10, 10],\n [10, 10, 10, 10, 10, 10, 10],\n [10, 10, 10, 10, 10, 10, 10],\n [10, 10, 10, 10, 10, 10, 10],\n [10, 10, 10, 10, 10]]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "arr = [10]*40\n",
    "size = 7\n",
    "partitions_count = len(arr) // size + (1 if len(arr) % size != 0 else 0)\n",
    "partitions = [arr[i * size: min(i * size + size, len(arr))] for i in range(partitions_count)]\n",
    "partitions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}